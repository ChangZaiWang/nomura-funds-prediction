{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20210-202202_PTT基金版.ipynb","provenance":[{"file_id":"1ll8_8IqHZH7nvYCftfMjiBWpFpua5DXh","timestamp":1651478058990}],"collapsed_sections":[],"authorship_tag":"ABX9TyPCDPTz9zliaMcV91asDLzu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["主程式碼"],"metadata":{"id":"nNwq-uyy7M8N"}},{"cell_type":"code","source":["def crawler(url):\n","  import requests\n","  from bs4 import BeautifulSoup\n","  headers = {'user-agent':\"123\"}\n","  res = requests.get(url,headers=headers)\n","  soup = BeautifulSoup(res.text,'html.parser')\n","  return soup\n"],"metadata":{"id":"uP5tSdYQ3MYq","executionInfo":{"status":"ok","timestamp":1652585818858,"user_tz":-480,"elapsed":309,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def pttfund_csv():\n","  #創造csv\n","  import csv\n","  \n","  with open('ptt_fund.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['主文/留言','作者','時間','標題','推/噓','內容'])"],"metadata":{"id":"wz1Dv07ivf2X","executionInfo":{"status":"ok","timestamp":1652585819266,"user_tz":-480,"elapsed":3,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def timer_articles(url):\n","  #判別文章時間，抓取狀態\n","  from datetime import datetime\n","  global start,end\n","\n","  soup = crawler(url)\n","  header = soup.find_all('span','article-meta-value')\n","  date=header[-1].text.replace('  ',\" \")\n","  \n","  time=datetime.strptime(date,\"%a %b %d %H:%M:%S %Y\")\n","  start=datetime.strptime(\"Fri Aug 20 23:59:59 2021\",\"%a %b %d %H:%M:%S %Y\")\n","  end=datetime.strptime(\"Tue Mar 1 00:00:00 2022\",\"%a %b %d %H:%M:%S %Y\")\n","\n","  if time < end:\n","    if time > start:\n","      return True,True \n","    else:\n","      return False,False #從新往舊文章爬，已全數爬取完畢\n","  else:\n","    return False,True #從新往舊文章爬，尚未開始"],"metadata":{"id":"w3g1o01rB8om","executionInfo":{"status":"ok","timestamp":1652585819266,"user_tz":-480,"elapsed":2,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def crawler_articles(url):\n","  #各別取得主文/留言\n","  from datetime import datetime\n","\n","  author,time,title,contents,date=get_maininfo(url)\n","\n","  #留言\n","  soup = crawler(url)\n","  article = soup.find_all('div','push')\n","  try:\n","    lastauthor=article[0].find('span', 'push-userid').getText()\n","  except:\n","    #文章沒有任何回覆\n","    lastauthor=''\n","\n","  if lastauthor == '':\n","    if '[新聞]' not in title and '訪談招募' not in title:\n","      article_csv(\"主文\",author,time,title,'無',contents) #將主文寫入csv \n","  else:\n","    article_csv(\"主文\",author,time,title,'無',contents) #將主文寫入csv\n","\n","\n","  pushtype='無'\n","  messages=''\n","  retitle=''\n","\n","  for i in article:\n","    author=i.find('span', 'push-userid').getText()# 目前的回覆者\n","    emotion=i.find('span', 'push-tag').getText().strip()\n","    if author == lastauthor:\n","      if emotion == \"噓\" or emotion == \"推\":\n","        #針對主題的新回覆\n","        pushtype=emotion\n","        author,time,messages=get_reinfo(i,date,url)\n","      else:\n","        #同一則留言的回覆\n","        messages+=i.find('span', 'f3 push-content').getText().replace(': ','')\n","    else:\n","      header = soup.find_all('span','article-meta-value')\n","      date=datetime.strptime(header[3].text,\"%a %b %d %H:%M:%S %Y\")\n","      if emotion == \"噓\" or emotion == \"推\":\n","        #確定上一個人留言完畢了\n","        if retitle ==\"\":\n","          article_csv(\"回覆\",lastauthor,time,title,pushtype,messages)\n","          messages=''\n","        else:\n","          article_csv(\"回覆\",lastauthor,time,retitle,pushtype,messages)\n","          retitle=''\n","          messages=''\n","        author,time,messages=get_reinfo(i,date,url)\n","      else:\n","        #新的人回覆上一個人的回覆\n","        article_csv(\"回覆\",lastauthor,time,title,'無',messages)\n","        retitle=messages\n","        datetext=str(date.strftime(\"%Y\"))+\"/\"+i.find('span', 'push-ipdatetime').getText().strip().replace('\\n','')+\":00\"\n","        messages = i.find('span', 'f3 push-content').getText().replace(': ','')\n","\n","    lastauthor=author\n","  if lastauthor != '':\n","    if retitle ==\"\":\n","      article_csv(\"回覆\",lastauthor,time,title,pushtype,messages)#將回覆寫入csv\n","    else:\n","      article_csv(\"回覆\",lastauthor,time,retitle,pushtype,messages)\n","      retitle=''\n","      messages=''"],"metadata":{"id":"Yfk_imhFGajE","executionInfo":{"status":"ok","timestamp":1652595370448,"user_tz":-480,"elapsed":304,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def get_maininfo(url):\n","  #取得主文資訊\n","  from datetime import datetime\n","  import pandas as pd\n","  soup = crawler(url)\n","  header = soup.find_all('span','article-meta-value')\n","\n","  author = header[0].text # 作者\n","  title = header[2].text # 標題\n","\n","  # 日期判斷\n","  basic = soup.find_all('span','f2')\n","  rewrite=False\n","  for i in range(len(basic)-1,1,-1):\n","    if \"編輯\" in basic[i].text:\n","      rewrite=True\n","      time=basic[i].text.replace('\\n','').split(\",\") \n","      date=datetime.strptime(time[1],\" %m/%d/%Y %H:%M:%S\")\n","      time=date.strftime(\"%Y-%m-%d %H:%M:%S\")\n","      break\n","  if not rewrite:\n","    date=datetime.strptime(header[3].text,\"%a %b %d %H:%M:%S %Y\") \n","    time=date.strftime(\"%Y-%m-%d %H:%M:%S\")#換成和dcard一樣的格式，2022-05-01 07:26:25\n","  \n","  # 內容\n","  main_container = soup.find(id='main-container')\n","  content = main_container.text.split('--')[0].split('\\n')[2:]\n","  contents = '\\n'.join(content)\n","  \n","  return author,time,title,contents,date"],"metadata":{"id":"MwinKDkNfvYj","executionInfo":{"status":"ok","timestamp":1652585819608,"user_tz":-480,"elapsed":3,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_reinfo(i,date,url):\n","  #取得留言資訊\n","  import requests\n","  from bs4 import BeautifulSoup\n","  from datetime import datetime\n","\n","  soup = crawler(url)\n","  article = soup.find_all('div','push')\n","\n","  author=i.find('span', 'push-userid').getText().strip() # 回覆者\n","  datetext=str(date.strftime(\"%Y\"))+\"/\"+i.find('span', 'push-ipdatetime').getText().replace('\\n','').strip()+\":00\" # 取得日期文字\n","  date=datetime.strptime(datetext,\"%Y/%m/%d %H:%M:%S\")\n","  time=date.strftime(\"%Y-%m-%d %H:%M:%S\")\n","  messages = i.find('span', 'f3 push-content').getText().replace(': ','')# 留言內容\n","\n","  return author,time,messages"],"metadata":{"id":"oqtmLb-qltQw","executionInfo":{"status":"ok","timestamp":1652585819609,"user_tz":-480,"elapsed":4,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def article_csv(type,author,time,title,pushtype,messages):\n","  #寫入csv\n","  import csv\n","  with open('ptt_fund.csv', 'a+', newline='', encoding='utf-8-sig') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow([type,author,time,title,pushtype,messages])"],"metadata":{"id":"sRtiAn8TWaVq","executionInfo":{"status":"ok","timestamp":1652585819609,"user_tz":-480,"elapsed":3,"user":{"displayName":"廖曉","userId":"05748637236513126021"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"HVYvyl38Izn1","executionInfo":{"status":"ok","timestamp":1652597360794,"user_tz":-480,"elapsed":1984556,"user":{"displayName":"廖曉","userId":"05748637236513126021"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"71c9b35a-5f88-4eb9-bbea-3635c48ef7da"},"outputs":[{"output_type":"stream","name":"stdout","text":["開始一頁 https://www.ptt.cc/bbs/Fund/index1088.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1087.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1086.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1085.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1084.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1083.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1082.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1081.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1080.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1079.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1078.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1077.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1076.html\n","開始一頁 https://www.ptt.cc/bbs/Fund/index1075.html\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","\n","url = \"https://www.ptt.cc/bbs/Fund/index1088.html\"\n","headers = {'user-agent':\"123\"}\n","soup = crawler(url)\n","pttfund_csv() #創建csv檔/覆蓋掉原內容\n","\n","while url!=\"\":\n","  print(\"開始一頁\",url)\n","  articles = soup.select('.title a') #取得頁面所有文章\n","  for i in range(len(articles)-1,0,-1):\n","    each_title=articles[i]\n","    article_url = \"https://www.ptt.cc\" + each_title['href'] #取得文章網址\n","\n","    #排除[公告]、版主聯署的文章\n","    if \"[公告]\" not in each_title.text and \"推薦人\" not in each_title.text and \"[連署板主]\" not in each_title.text:\n","      \n","      #判斷文章是否在要的時間區間內\n","      timezone, status = timer_articles(article_url) \n","      if timezone:\n","        article_data=crawler_articles(article_url) #抓取頁面內容並寫入csv\n","        time.sleep(5) #和dcard一樣5秒爬1次新的主文\n","\n","  if status:\n","    paging = soup.select('.btn-group-paging a')\n","    last_url = \"https://www.ptt.cc\" + paging[1]['href']\n","    url = last_url\n","    time.sleep(1) #和dcard一樣停1秒\n","    soup = crawler(url)\n","  else:\n","    url=\"\""]}]}